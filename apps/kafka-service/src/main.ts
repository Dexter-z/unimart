import { kafka } from "@packages/utils/kafka";
import { updateUserAnalytics } from "./services/analytics.service";

// console.log('ðŸ“š Imports loaded successfully');
// console.log('âš™ï¸ Creating consumer...');

// Log Kafka environment variables for debugging
console.log('--- Kafka ENV DEBUG ---');
console.log('KAFKA_BROKER:', process.env.KAFKA_BROKER);
console.log('KAFKA_USERNAME:', process.env.KAFKA_USERNAME);
console.log('KAFKA_PASSWORD:', process.env.KAFKA_PASSWORD ? '***' : undefined);
console.log('KAFKA_SSL_CA_PATH:', process.env.KAFKA_SSL_CA_PATH);
console.log('-----------------------');

const consumer = kafka.consumer({ 
  groupId: 'user-events-group'
});

const eventQueue: any[] = [];

const processQueue = async () => {
  // console.log('ðŸ”„ processQueue called, eventQueue length:', eventQueue.length);
  
  if (eventQueue.length === 0) {
    return;
  }
  
  // console.log(`ðŸ“¦ Processing ${eventQueue.length} events...`);
  const events = [...eventQueue]

  eventQueue.length = 0;

  for(const event of events){
    // console.log(`âš¡ Processing event: ${event.action} for user: ${event.userId}`);
    
    if(event.action === "shop_visit"){
      //Update shop visitor analytics
      // console.log('ðŸª Shop visit event - skipping for now');
      continue;
    }

    const validActions = [
      "add_to_wishlist",
      "add_to_cart",
      "product_view",
      "remove_from_wishlist",
      "remove_from_cart"
    ];

    if(!event.action || !validActions.includes(event.action)){
      // console.log(`âš ï¸ Invalid action: ${event.action}, skipping`);
      continue;
    }

    try {
      // console.log(`ðŸ”„ About to call updateUserAnalytics with:`, event);
      await updateUserAnalytics(event);
      // console.log(`âœ… Successfully processed ${event.action} for user ${event.userId}`);
    } catch (error: any) {
      // console.error("âŒ Error processing event:", error?.message || error);
      // console.error("ðŸ“‹ Full error stack:", error?.stack);
      // console.error("ðŸ“‹ Event data:", event);
    }
  }
}

setInterval(processQueue, 3000); //Every 3 seconds

// Add a heartbeat log every 30 seconds to show service is alive
// setInterval(() => {
//   console.log(`ðŸ’“ Kafka service alive - Queue: ${eventQueue.length} events`);
// }, 30000);

//kafka consumer for user events
export const consumeKafkaMessages = async () => {
  try {
    // console.log('ðŸ”Œ Connecting to Kafka consumer...');
    await consumer.connect();
    // console.log('âœ… Consumer connected successfully');
    
    // console.log('ðŸ“¡ Subscribing to users-events topic...');
    await consumer.subscribe({ topic: 'users-events', fromBeginning: false });
    // console.log('âœ… Subscribed to users-events topic');
    
    // console.log('ðŸŽ§ Starting to consume messages...');
    await consumer.run({
      eachMessage: async({ topic, partition, message }) => {
        if(!message.value){
          // console.log('âš ï¸ Received empty message');
          return;
        }
        
        try {
          const event = JSON.parse(message.value.toString());
          // console.log('ðŸ“¨ Received Kafka event:', { topic, partition, event });
          eventQueue.push(event);
          // console.log(`ðŸ“¦ Event added to queue (${eventQueue.length} total)`);
        } catch (parseError: any) {
          // console.error('âŒ Failed to parse message:', parseError?.message);
          // console.error('âŒ Raw message:', message.value?.toString());
        }
      }
    });
  } catch (error: any) {
    // console.error('âŒ Kafka consumer error:', error?.message || error);
    // console.error('âŒ Full error stack:', error?.stack);
    
    // Retry connection after 10 seconds
    // console.log('ðŸ”„ Retrying connection in 10 seconds...');
    setTimeout(() => {
      consumeKafkaMessages().catch(console.error);
    }, 10000);
  }
}

// Handle graceful shutdown
process.on('SIGTERM', async () => {
  // console.log('ðŸ“´ Shutting down Kafka consumer...');
  try {
    await consumer.disconnect();
    // console.log('âœ… Kafka consumer disconnected');
  } catch (error) {
    // console.error('âŒ Error disconnecting:', error);
  }
  process.exit(0);
});

process.on('SIGINT', async () => {
  // console.log('ðŸ“´ Shutting down Kafka consumer...');
  try {
    await consumer.disconnect();
    // console.log('âœ… Kafka consumer disconnected');
  } catch (error) {
    // console.error('âŒ Error disconnecting:', error);
  }
  process.exit(0);
});

// console.log('ðŸš€ Starting Kafka service...');
// console.log('ðŸŒ Environment check:');
// console.log('- NODE_ENV:', process.env.NODE_ENV || 'not set');
// console.log('- KAFKA_API_KEY:', process.env.KAFKA_API_KEY ? `âœ… Set (${process.env.KAFKA_API_KEY})` : 'âŒ Missing');
// console.log('- KAFKA_API_SECRET:', process.env.KAFKA_API_SECRET ? `âœ… Set (${process.env.KAFKA_API_SECRET?.substring(0,10)}...)` : 'âŒ Missing');
// console.log('- DATABASE_URL:', process.env.DATABASE_URL ? 'âœ… Set' : 'âŒ Missing');
// Start Kafka consumer
consumeKafkaMessages().catch(console.error);

// Minimal HTTP server for Render web service
import http from "http";
const port = process.env.PORT || 8080;
const server = http.createServer((req, res) => {
  res.writeHead(200, { 'Content-Type': 'text/plain' });
  res.end('Kafka service is running.');
});
server.listen(port, () => {
  console.log(`Kafka service HTTP server listening on port ${port}`);
});